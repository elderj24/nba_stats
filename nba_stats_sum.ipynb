{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c77f2c-a99c-4022-81ad-21c833729e40",
   "metadata": {},
   "source": [
    "NBA Analysis\n",
    "Analyzes advanced statistics, creates a regression model to predict salary, and offers preliminary assessment of under-and-over-valued players based on actual salaries relative to the predicted salaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37716df2-e579-4b98-aca1-2b9ceb11e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Import libraries\n",
    "import pandas as pd, matplotlib.pyplot as plt, seaborn as sns, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dea0e0-5567-4e12-be2b-001ff07ac815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 load csv files\n",
    "# Note: Full script (available in Github repo) scrapes (i) advanced stats and (ii) salary data from Basketballreference.com and puts them into two separate csv files.\n",
    "# This summary analysis uploads the two csv files as the starting point\n",
    "df_stats = pd.read_csv('nba_advanced_stats_2025.csv')\n",
    "df_salary = pd.read_csv('nba_player_salaries_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040080d-d300-42bb-9d1f-69d23e381744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Explore data structure\n",
    "print(df_stats.shape, df_salary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa859bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Clean the salary data set \n",
    "\n",
    "print(df_salary.isnull().sum()) # check for missing values\n",
    "\n",
    "# drop rows with missing salary and remove duplicate players, keeping the first occurrence\n",
    "df_salary_updated = df_salary.dropna(subset=['Salary_2025_26']).drop_duplicates(subset=['Player'], keep='first').reset_index(drop=True)\n",
    "\n",
    "print(f\"Duplicate players in salary data: {df_salary_updated['Player'].duplicated().sum()}\") # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 clean the stats data set\n",
    "\n",
    "# check for duplicates in Player names\n",
    "print(f\"Duplicate players in stats data: {df_stats['Player'].duplicated().sum()}\")\n",
    "\n",
    "# identify players who appear multiple times\n",
    "player_counts = df_stats['Player'].value_counts()\n",
    "print(player_counts)\n",
    "duplicated_players = player_counts[player_counts > 1].index\n",
    "print(duplicated_players)\n",
    "\n",
    "# if players have multile entries, keep the instance with 2TM or 3TM, otherwise keep the first occurrence\n",
    "def keep_combined_stats(group):\n",
    "    # check if there's a 2TM or 3TM entry\n",
    "    combined_entry = group[group['Team'].isin(['2TM', '3TM'])]\n",
    "    if len(combined_entry) > 0:\n",
    "        return combined_entry\n",
    "    else:\n",
    "        # if no combined entry, return the original entry \n",
    "        return group \n",
    "    \n",
    "# apply the function to each group of duplicated players\n",
    "df_stats_cleaned = df_stats.groupby('Player', group_keys=False).apply(keep_combined_stats)\n",
    "\n",
    "# reset index after groupby operation\n",
    "df_stats_cleaned = df_stats_cleaned.reset_index(drop=True)\n",
    "\n",
    "# check for duplicated players again\n",
    "print(f\"Duplicate players in cleaned stats data: {df_stats_cleaned['Player'].duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Merge datasets on Player name\n",
    "df_merged = pd.merge(df_stats_cleaned, df_salary_updated[['Player', 'Salary_2025_26']], on='Player', how='inner')\n",
    "df_merged['Salary_Millions'] = df_merged['Salary_2025_26'] / 1_000_000\n",
    "print(f\"Merged dataset shape: {df_merged.shape}\")\n",
    "print(f\"Duplicate players in cleaned stats data: {df_merged['Player'].duplicated().sum()}\")\n",
    "print(df_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Create histograms of key features\n",
    "features = ['PER', 'WS', 'VORP', 'Salary_Millions']\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    sns.histplot(df_merged[feature], bins=30, kde=True, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribution of {feature}')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67199090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 scatter plot of PER, WS and VORP vs. Salary with best fit lines \n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Function to add best fit line\n",
    "def add_best_fit(ax, x, y):\n",
    "    # Remove any NaN values\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x_clean = x[mask]\n",
    "    y_clean = y[mask]\n",
    "    \n",
    "    # Calculate best fit line\n",
    "    z = np.polyfit(x_clean, y_clean, 1)\n",
    "    p = np.poly1d(z)\n",
    "    \n",
    "    # Add line to plot\n",
    "    ax.plot(x_clean, p(x_clean), \"r-\", linewidth=2, label=f'Best fit: y={z[0]:.2f}x+{z[1]:.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "# Scatter plot 1: PER vs. Salary\n",
    "axes[0].scatter(df_merged['PER'], df_merged['Salary_Millions'], alpha=0.6)\n",
    "add_best_fit(axes[0], df_merged['PER'].values, df_merged['Salary_Millions'].values)\n",
    "axes[0].set_xlabel('PER')\n",
    "axes[0].set_ylabel('Salary ($ Millions)')\n",
    "axes[0].set_title('PER vs. Salary')\n",
    "\n",
    "# Scatter plot 2: WS vs. Salary\n",
    "axes[1].scatter(df_merged['WS'], df_merged['Salary_Millions'], alpha=0.6)\n",
    "add_best_fit(axes[1], df_merged['WS'].values, df_merged['Salary_Millions'].values)\n",
    "axes[1].set_xlabel('WS (Win Shares)')\n",
    "axes[1].set_ylabel('Salary ($ Millions)')\n",
    "axes[1].set_title('Win Shares vs. Salary')\n",
    "\n",
    "# Scatter plot 3: VORP vs. Salary\n",
    "axes[2].scatter(df_merged['VORP'], df_merged['Salary_Millions'], alpha=0.6)\n",
    "add_best_fit(axes[2], df_merged['VORP'].values, df_merged['Salary_Millions'].values)\n",
    "axes[2].set_xlabel('VORP')\n",
    "axes[2].set_ylabel('Salary ($ Millions)')\n",
    "axes[2].set_title('VORP vs. Salary')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ba3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 Create correlation matrix for PER, WS, VORP, and Salary\n",
    "correlation_matrix = df_merged[['PER', 'WS', 'VORP', 'Salary_Millions']].corr()\n",
    "\n",
    "# Create a heatmap for better visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,  # Show correlation values\n",
    "            fmt='.3f',   # Format to 3 decimal places\n",
    "            cmap='coolwarm',  # Color scheme\n",
    "            center=0,    # Center colormap at 0\n",
    "            square=True,  # Make cells square\n",
    "            linewidths=1,  # Add gridlines\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix: Performance Metrics vs Salary', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 create a multi-linear regression analysis to predict salaries\n",
    "\n",
    "# Select features for the model (all numeric columns except salary columns)\n",
    "features_to_use = ['PER', 'TS%', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', \n",
    "                   'MP', 'G', 'USG%', 'AST%', 'TRB%']\n",
    "\n",
    "# Remove rows with missing values in the features we're using\n",
    "df_model = df_merged[features_to_use + ['Salary_Millions']].dropna()\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_model[features_to_use]\n",
    "y = df_model['Salary_Millions']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  R² Score: {r2_score(y_train, y_pred_train):.4f}\")\n",
    "print(f\"  RMSE: ${np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f}M\")\n",
    "print(f\"  MAE: ${mean_absolute_error(y_train, y_pred_train):.2f}M\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  R² Score: {r2_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  RMSE: ${np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}M\")\n",
    "print(f\"  MAE: ${mean_absolute_error(y_test, y_pred_test):.2f}M\")\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "plt.xlabel('Actual Salary ($ Millions)')\n",
    "plt.ylabel('Predicted Salary ($ Millions)')\n",
    "plt.title('Predicted vs Actual Salaries (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc60531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 Create a dataframe with actual vs predicted salaries\n",
    "# Get the player names and age from the original df_merged using the index\n",
    "player_names = df_merged.loc[X_test.index, 'Player']\n",
    "player_ages = df_merged.loc[X_test.index, 'Age']\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Player': player_names.values,\n",
    "    'Age': player_ages.values,\n",
    "    'Actual_Salary_Millions': y_test.values,\n",
    "    'Predicted_Salary_Millions': y_pred_test,\n",
    "    'Difference_Millions': y_test.values - y_pred_test\n",
    "})\n",
    "\n",
    "# Sort by difference to identify overpaid and underpaid players\n",
    "results_df = results_df.sort_values('Difference_Millions', ascending=False)\n",
    "\n",
    "print(\"==\" * 40)\n",
    "print(\"TOP 3 OVERPAID PLAYERS (Actual > Predicted)\")\n",
    "print(\"==\" * 40)\n",
    "print(results_df.head(3)[['Player', 'Age', 'Actual_Salary_Millions', \n",
    "                          'Predicted_Salary_Millions', 'Difference_Millions']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"==\" * 40)\n",
    "print(\"TOP 3 UNDERPAID PLAYERS (Predicted > Actual)\")\n",
    "print(\"==\" * 40)\n",
    "print(results_df.tail(3)[['Player', 'Age', 'Actual_Salary_Millions', \n",
    "                          'Predicted_Salary_Millions', 'Difference_Millions']].to_string(index=False))\n",
    "\n",
    "# Optionally save to CSV\n",
    "results_df.to_csv('salary_predictions.csv', index=False)\n",
    "print(\"\\nFull results saved to 'salary_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
